
            <h2 id="section-75">üï¥Ô∏è Related Work History</h2>
      <p>
        I sold and configured MS-DOS and CP/M-80 machines the first five
        years of my IT career.</p>
      <div class="centerpage">
        <figure>
          <img src="/images/unidiag.png" alt="Unicenter TNG Automation">
          <figcaption aria-hidden="true">Unicenter TNG
            Automation</figcaption>
        </figure>
      </div>
      <div class="figclick">
        <a href="/images/unidiag.png">Click here for large version.</a>
      </div>
      <p>After I got an undergraduate degree in math, my career moved
        on to enterprise IT with the widespread adoption of networking
        in 1994. I got a job at an IT consulting firm as a technician
        and helpdesk for the main and satellite office that then morphed
        from an initial joining of four founding companies across six
        cities, into a nation-wide consulting company in 25 cities. The
        complexity of the resulting system required automation and third
        party software to manage. I learned an early enterprise IT
        system management platform, Unicenter TNG, but I added my own
        automation, as the GUI was cumbersome. I created Fig. 37 in
        1999. In 2001, I got a job working for a startup that provided
        inventory management and combined purchasing for health food
        stores. Most of the stores were connected with dial-up lines.
        With a crew of three, I deployed and managed 150 stores with
        POS/PC systems, centrally updated inventory databases and
        frequently changing software at the stores, including Palm OS
        devices that handled the scanning. This, combined with the
        Unicenter TNG work I had done previously, gave me a decent
        insight into the coming DevOps perspective that infrastructure
        was code.</p>
      <div class="centerpage">
        <figure>
          <img src="/images/esystem.png" alt="Early DevOps">
          <figcaption aria-hidden="true">Early DevOps</figcaption>
        </figure>
      </div>
      <div class="figclick">
        <a href="/images/esystem.png">Click here for large version.</a>
      </div>
      I created Fig. 38 in 2002. It shows CI/CD to 150 stores over
      <strong>dial-up lines</strong>. I then got a job in 2003 for a
      medical ASP (Application Service Provider, what they called
      cloud before it became SaaS). In addition to building out and
      monitoring the front-end servers, I worked on their remit
      downloads, verification, and processing. While there, I created
      my first data flow, documenting the system I worked on, shown in
      Fig. 39. In 2006 I got a job as a system architect at a global
      law firm. Within the first two weeks of my job at the firm, I
      jumped right into a critical project. They were trying to solve
      the problem of running discovery apps over latent links. They
      also had a horrible network that aggravated this, but they
      weren‚Äôt aware of just how bad it was, and wanted to buy an app
      to solve a particular symptom. The CIO set up a meeting, and I
      met along with my assigned project manager to establish the
      timeline for rollout on my first week on the job.
      <div class="centerpage">
        <figure>
          <img src="/images/remit.png" alt="Remit Diagram from 2005">
          <figcaption aria-hidden="true">Remit Diagram from
            2005</figcaption>
        </figure>
      </div>
      <div class="figclick">
        <a href="/images/remit.svg">Click here for vector version.</a>
      </div>
      <p>The CIO put me on the spot, and I figured no big deal, I
        would figure out how it worked, what people needed the first
        week, get the vendor recommendations, and put it in by week two.
        My project manager, who had previously worked as a project
        manager at Rockwell International on the space shuttle, was not
        happy that I had answered in this way. I told her I would back
        it up, and responded with a two paragraph email that had bullet
        points for how I saw the project being implemented. She came
        back, waving the email at me, and said that what I gave her was
        entirely unacceptable. I was confused and thought she was
        abusing me (she wasn‚Äôt). I went to my boss, a wonderful boss
        that was generous and thought broadly. She gave me an example of
        what was needed. This is how I was introduced to the concept of
        a solution design document. It is a form of knowledge that
        describes where we are now and where we want to be in standard
        terms, so that everybody can agree. Not every aspect needed to
        be filled out. It varied by solution. In the years that
        followed, I realized that if the information applied to a system
        at all, at some point during the procurement, deployment, or
        operation of the system, the aspects would come up. From that
        time forward, I insisted on creating an appropriately scaled
        solution description for every medium+ project I worked on. My
        work experience so far showed the value of this level of detail.
        My insistence on solution description documentation, though, was
        increasingly received poorly over time. It was perceived as a
        drag on ‚Äúagility‚Äù.</p>
      <p>I moved on to a technical project manager role, where I moved
        a point of sale system to cloud for a brick and mortar retailer,
        and moved on again to a pioneer of internet search that was
        re-inventing itself after losing the search wars to the current
        apex cloud search engine. I was in charge of all monitoring.
        There was a brilliant person in charge of IT that had replaced
        the typical relational database reporting with decomposed data
        that was then fed into reporting and analysis engines, kind of
        like the modern Elastic. I realized that key-value pairs in
        event streams could be much more effectively analyzed than
        canned relational reports. This is the idea of Splunk, and I
        evangelized Splunk <span class="citation" data-cites="noauthor_splunk_2023">(<a href="#ref-noauthor_splunk_2023"
            role="doc-biblioref"><span>‚ÄúSplunk‚Äù</span> 2023</a>)</span>. I
        also struggled with the simplest tasks of reporting on all
        monitors across thousands of servers. Nodes in a monitoring
        system do not fit well into a relational database. Most machines
        are different, even if they are the same model. I found that
        NoSQL approaches worked better for reporting on monitor classes.
        I was hot on the key-value pair stream analysis track. I moved
        on to another startup, where I could do anything I wanted in IT
        as long as it was fast enough and fit the requirements of the
        money that backed us (large banks). I struggled with my main
        developer to build out an analysis platform for an upcoming
        launch. I finally just did it all myself in two weeks using
        GNU/Linux, BASH, Perl to capture and normalize the data, and ran
        it all into Splunk as key-value pairs, happily proving my ideas
        from my previous job. I used my skills in system documentation
        to demonstrate to the banks our systems were secure and
        protected.</p>
